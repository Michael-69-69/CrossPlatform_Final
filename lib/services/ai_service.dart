// lib/services/ai_service.dart
import 'dart:convert';
import 'package:http/http.dart' as http;
import 'package:flutter_dotenv/flutter_dotenv.dart';

enum AIProvider { openai, gemini, groq }
enum QuizDifficulty { easy, medium, hard }
enum QuestionType { multipleChoice, trueFalse, shortAnswer, fillInBlank }

class AIService {
  static final AIService _instance = AIService._internal();
  factory AIService() => _instance;
  AIService._internal();

  static AIProvider _provider = AIProvider.gemini;
  
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // COOLDOWN MANAGEMENT
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  static DateTime? _lastRequestTime;
  static const int _cooldownSeconds = 10;
  
  static bool get isInCooldown {
    if (_lastRequestTime == null) return false;
    return DateTime.now().difference(_lastRequestTime!).inSeconds < _cooldownSeconds;
  }
  
  static int get remainingCooldownSeconds {
    if (_lastRequestTime == null) return 0;
    final elapsed = DateTime.now().difference(_lastRequestTime!).inSeconds;
    return (_cooldownSeconds - elapsed).clamp(0, _cooldownSeconds);
  }
  
  static void _recordRequest() {
    _lastRequestTime = DateTime.now();
  }
  
  // API Key
  static String get _apiKey {
    final envKey = dotenv.env['GEMINI_API_KEY'] ?? '';
    if (envKey.isNotEmpty) return envKey;
    return '';
  }

  static String get _model {
    switch (_provider) {
      case AIProvider.openai:
        return 'gpt-3.5-turbo';
      case AIProvider.gemini:
        return 'gemini-2.0-flash';
      case AIProvider.groq:
        return 'llama-3.1-70b-versatile';
    }
  }

  static String get _baseUrl {
    switch (_provider) {
      case AIProvider.openai:
        return 'https://api.openai.com/v1/chat/completions';
      case AIProvider.gemini:
        return 'https://generativelanguage.googleapis.com/v1beta/models/$_model:generateContent';
      case AIProvider.groq:
        return 'https://api.groq.com/openai/v1/chat/completions';
    }
  }

  static bool get isConfigured {
    final key = _apiKey;
    return key.isNotEmpty && key.length > 10;
  }

  static void setProvider(AIProvider provider) {
    _provider = provider;
  }

  static Future<void> initialize() async {
    print('ğŸ¤– Initializing AI Service...');
    print('ğŸ¤– Using model: $_model');
    print('ğŸ¤– isConfigured: $isConfigured');
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // CORE CHAT COMPLETION (FIXED!)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  static Future<String> chat({
    required String message,
    String? systemPrompt,
    List<Map<String, String>>? conversationHistory,
    double temperature = 0.7,
    int maxTokens = 4096,
  }) async {
    if (!isConfigured) {
      throw Exception('AI service not configured. Please add GEMINI_API_KEY to .env');
    }
    
    // Record request for cooldown
    _recordRequest();

    final url = '$_baseUrl?key=$_apiKey';
    
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // FIX: Use Gemini's systemInstruction for proper context injection
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    final contents = <Map<String, dynamic>>[];
    
    // Add conversation history
    if (conversationHistory != null && conversationHistory.isNotEmpty) {
      for (final msg in conversationHistory) {
        contents.add({
          'role': msg['role'] == 'assistant' ? 'model' : 'user',
          'parts': [{'text': msg['content']}],
        });
      }
    }
    
    // Add current message
    contents.add({
      'role': 'user',
      'parts': [{'text': message}],
    });

    // Build request body with systemInstruction (THE FIX!)
    final requestBody = <String, dynamic>{
      'contents': contents,
      'generationConfig': {
        'temperature': temperature,
        'maxOutputTokens': maxTokens,
      },
    };
    
    // Add system instruction if provided (THIS IS THE KEY FIX!)
    if (systemPrompt != null && systemPrompt.isNotEmpty) {
      requestBody['systemInstruction'] = {
        'parts': [{'text': systemPrompt}]
      };
    }

    print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    print('ğŸ¤– SENDING TO GEMINI API:');
    print('   Model: $_model');
    print('   System prompt length: ${systemPrompt?.length ?? 0} chars');
    print('   Message: $message');
    print('   History: ${conversationHistory?.length ?? 0} messages');
    print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

    final response = await http.post(
      Uri.parse(url),
      headers: {'Content-Type': 'application/json'},
      body: jsonEncode(requestBody),
    );

    if (response.statusCode != 200) {
      print('âŒ Gemini error: ${response.body}');
      
      // Parse error for better message
      try {
        final errorData = jsonDecode(response.body);
        final errorMessage = errorData['error']?['message'] ?? 'Unknown error';
        throw Exception('Gemini API error: $errorMessage');
      } catch (e) {
        throw Exception('Gemini API error: ${response.statusCode}');
      }
    }

    final data = jsonDecode(response.body);
    
    if (data['candidates'] == null || (data['candidates'] as List).isEmpty) {
      if (data['promptFeedback']?['blockReason'] != null) {
        throw Exception('Content blocked: ${data['promptFeedback']['blockReason']}');
      }
      throw Exception('No response from AI');
    }
    
    final candidate = data['candidates'][0];
    
    if (candidate['finishReason'] == 'SAFETY') {
      throw Exception('Response blocked due to safety filters');
    }
    
    if (candidate['content'] == null || candidate['content']['parts'] == null) {
      throw Exception('Invalid response format from AI');
    }
    
    final responseText = candidate['content']['parts'][0]['text'] as String;
    
    print('âœ… AI Response received: ${responseText.length} chars');
    
    return responseText;
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ¤– AI LEARNING CHATBOT WITH APP CONTEXT (FIXED!)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  static Future<String> learningAssistantWithContext({
    required String question,
    required String courseName,
    String? courseDescription,
    String? appContext,
    String? materialContext,
    List<Map<String, String>>? conversationHistory,
    String language = 'vi',
  }) async {
    final isVi = language == 'vi';
    
    // Build a comprehensive system prompt with ALL context
    final systemPrompt = isVi ? '''
Báº N LÃ€ TRá»¢ LÃ AI CHO Há»† THá»NG QUáº¢N LÃ Há»ŒC Táº¬P (LMS).
${courseDescription != null ? 'Äang xem mÃ´n: $courseDescription' : ''}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
QUAN TRá»ŒNG: Dá»® LIá»†U Há»† THá»NG BÃŠN DÆ¯á»šI LÃ€ NGUá»’N THÃ”NG TIN CHÃNH XÃC.
Báº N PHáº¢I Sá»¬ Dá»¤NG Dá»® LIá»†U NÃ€Y Äá»‚ TRáº¢ Lá»œI CÃ‚U Há»I Cá»¦A NGÆ¯á»œI DÃ™NG.
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

$appContext

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HÆ¯á»šNG DáºªN TRáº¢ Lá»œI:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. LUÃ”N sá»­ dá»¥ng dá»¯ liá»‡u há»‡ thá»‘ng á»Ÿ trÃªn Ä‘á»ƒ tráº£ lá»i
2. Khi Ä‘Æ°á»£c há»i vá» sá»‘ liá»‡u, Ä‘áº¿m CHÃNH XÃC tá»« dá»¯ liá»‡u
3. Khi Ä‘Æ°á»£c há»i vá» sinh viÃªn/nhÃ³m, tÃ¬m trong pháº§n DANH SÃCH
4. Náº¿u khÃ´ng tÃ¬m tháº¥y thÃ´ng tin, nÃ³i rÃµ "KhÃ´ng cÃ³ dá»¯ liá»‡u vá»..."
5. KHÃ”NG bá»‹a thÃ´ng tin khÃ´ng cÃ³ trong dá»¯ liá»‡u
6. Tráº£ lá»i ngáº¯n gá»n, dÃ¹ng markdown: **bold**, *italic*, - list
7. Khi liá»‡t kÃª, dÃ¹ng bullet points

${materialContext != null ? 'TÃ€I LIá»†U THAM KHáº¢O:\n$materialContext' : ''}
''' : '''
YOU ARE AN AI ASSISTANT FOR A LEARNING MANAGEMENT SYSTEM (LMS).
${courseDescription != null ? 'Currently viewing: $courseDescription' : ''}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
IMPORTANT: THE SYSTEM DATA BELOW IS YOUR ACCURATE SOURCE OF TRUTH.
YOU MUST USE THIS DATA TO ANSWER USER QUESTIONS.
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

$appContext

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RESPONSE GUIDELINES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. ALWAYS use the system data above to answer questions
2. When asked about numbers, count ACCURATELY from the data
3. When asked about students/groups, look in the LIST sections
4. If information is not found, say "No data available for..."
5. DO NOT make up information not in the data
6. Keep responses concise, use markdown: **bold**, *italic*, - lists
7. Use bullet points when listing items

${materialContext != null ? 'REFERENCE MATERIALS:\n$materialContext' : ''}
''';

    print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    print('ğŸ“¤ learningAssistantWithContext called');
    print('   Question: $question');
    print('   System prompt length: ${systemPrompt.length} chars');
    print('   App context length: ${appContext?.length ?? 0} chars');
    print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

    return await chat(
      message: question,
      systemPrompt: systemPrompt,
      conversationHistory: conversationHistory,
      temperature: 0.3, // Lower temperature for more accurate answers
      maxTokens: 4096,
    );
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ¤– AI LEARNING CHATBOT (Basic - no app context)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  static Future<String> learningAssistant({
    required String question,
    required String courseName,
    String? courseDescription,
    String? materialContext,
    List<Map<String, String>>? conversationHistory,
    String language = 'vi',
  }) async {
    final systemPrompt = '''
Báº¡n lÃ  trá»£ lÃ½ há»c táº­p AI thÃ´ng minh cho mÃ´n há»c "$courseName".
${courseDescription != null ? 'MÃ´ táº£ mÃ´n há»c: $courseDescription' : ''}

Nhiá»‡m vá»¥ cá»§a báº¡n:
1. Tráº£ lá»i cÃ¢u há»i cá»§a sinh viÃªn má»™t cÃ¡ch rÃµ rÃ ng, dá»… hiá»ƒu
2. Giáº£i thÃ­ch cÃ¡c khÃ¡i niá»‡m phá»©c táº¡p báº±ng vÃ­ dá»¥ thá»±c táº¿
3. Khuyáº¿n khÃ­ch sinh viÃªn tÆ° duy pháº£n biá»‡n
4. Náº¿u khÃ´ng cháº¯c cháº¯n, hÃ£y thá»«a nháº­n vÃ  gá»£i Ã½ nguá»“n tham kháº£o
5. Sá»­ dá»¥ng ngÃ´n ngá»¯ ${language == 'vi' ? 'tiáº¿ng Viá»‡t' : 'English'}

${materialContext != null ? 'TÃ i liá»‡u tham kháº£o:\n$materialContext' : ''}

HÃ£y tráº£ lá»i ngáº¯n gá»n, sÃºc tÃ­ch nhÆ°ng Ä‘áº§y Ä‘á»§ thÃ´ng tin. Sá»­ dá»¥ng markdown Ä‘á»ƒ format (**bold**, *italic*, - list).
''';

    return await chat(
      message: question,
      systemPrompt: systemPrompt,
      conversationHistory: conversationHistory,
      temperature: 0.7,
    );
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ“ AI QUIZ GENERATOR
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Add this after generateQuizQuestions method:

  /// Validate generated questions
  static List<Map<String, dynamic>> validateQuestions(List<Map<String, dynamic>> questions) {
    final validated = <Map<String, dynamic>>[];
    
    for (final q in questions) {
      if (q['question'] == null || (q['question'] as String).isEmpty) continue;
      if (q['correctAnswer'] == null) continue;
      
      if (q['type'] == 'multipleChoice') {
        if (q['options'] == null || (q['options'] as List).length < 2) continue;
      }
      
      validated.add(q);
    }
    
    return validated;
  }


  static Future<List<Map<String, dynamic>>> generateQuizQuestions({
    required String material,
    required int numberOfQuestions,
    required QuizDifficulty difficulty,
    required List<QuestionType> questionTypes,
    String? topic,
    String language = 'vi',
  }) async {
    final difficultyDesc = {
      QuizDifficulty.easy: 'Dá»… - cÃ¢u há»i cÆ¡ báº£n, kiá»ƒm tra kiáº¿n thá»©c ná»n táº£ng',
      QuizDifficulty.medium: 'Trung bÃ¬nh - cÃ¢u há»i yÃªu cáº§u hiá»ƒu vÃ  Ã¡p dá»¥ng',
      QuizDifficulty.hard: 'KhÃ³ - cÃ¢u há»i phÃ¢n tÃ­ch, tá»•ng há»£p, sÃ¡ng táº¡o',
    };

    final typeDesc = questionTypes.map((t) {
      switch (t) {
        case QuestionType.multipleChoice:
          return 'Tráº¯c nghiá»‡m (4 Ä‘Ã¡p Ã¡n A, B, C, D)';
        case QuestionType.trueFalse:
          return 'ÄÃºng/Sai';
        case QuestionType.shortAnswer:
          return 'Tá»± luáº­n ngáº¯n';
        case QuestionType.fillInBlank:
          return 'Äiá»n vÃ o chá»— trá»‘ng';
      }
    }).join(', ');

    final prompt = '''
Dá»±a trÃªn tÃ i liá»‡u sau, hÃ£y táº¡o $numberOfQuestions cÃ¢u há»i kiá»ƒm tra.

TÃ€I LIá»†U:
$material

YÃŠU Cáº¦U:
- Äá»™ khÃ³: ${difficultyDesc[difficulty]}
- Loáº¡i cÃ¢u há»i: $typeDesc
${topic != null ? '- Chá»§ Ä‘á» táº­p trung: $topic' : ''}
- NgÃ´n ngá»¯: ${language == 'vi' ? 'Tiáº¿ng Viá»‡t' : 'English'}

Äá»ŠNH Dáº NG OUTPUT (chá»‰ JSON array, khÃ´ng cÃ³ markdown hay text khÃ¡c):
[{"question":"Ná»™i dung cÃ¢u há»i","type":"multipleChoice","difficulty":"medium","options":["A. ...","B. ...","C. ...","D. ..."],"correctAnswer":"A","explanation":"Giáº£i thÃ­ch","points":1}]

CHá»ˆ TRáº¢ Vá»€ JSON ARRAY, KHÃ”NG CÃ“ TEXT KHÃC.
''';

    final response = await chat(message: prompt, temperature: 0.5, maxTokens: 4096);

    try {
      String jsonStr = response.trim();
      
      if (jsonStr.contains('```json')) {
        jsonStr = jsonStr.split('```json')[1].split('```')[0].trim();
      } else if (jsonStr.contains('```')) {
        jsonStr = jsonStr.split('```')[1].split('```')[0].trim();
      }
      
      final startIndex = jsonStr.indexOf('[');
      final endIndex = jsonStr.lastIndexOf(']');
      if (startIndex != -1 && endIndex != -1) {
        jsonStr = jsonStr.substring(startIndex, endIndex + 1);
      }
      
      final List<dynamic> questions = jsonDecode(jsonStr);
      return questions.map((q) => Map<String, dynamic>.from(q)).toList();
    } catch (e) {
      print('Error parsing quiz: $e');
      return [];
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ“š AI MATERIAL SUMMARIZER
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  static Future<Map<String, dynamic>> summarizeMaterial({
    required String content,
    String? title,
    bool includeKeyPoints = true,
    bool includeQuestions = true,
    String language = 'vi',
  }) async {
    final prompt = '''
HÃ£y tÃ³m táº¯t tÃ i liá»‡u há»c táº­p sau:

${title != null ? 'TIÃŠU Äá»€: $title\n' : ''}
Ná»˜I DUNG:
$content

Tráº£ vá» JSON vá»›i format (chá»‰ JSON, khÃ´ng markdown):
{"summary":"TÃ³m táº¯t ngáº¯n gá»n (2-3 Ä‘oáº¡n)","keyPoints":["Äiá»ƒm chÃ­nh 1","Äiá»ƒm chÃ­nh 2"],"concepts":[{"term":"Thuáº­t ngá»¯","definition":"Äá»‹nh nghÄ©a"}],"reviewQuestions":["CÃ¢u há»i Ã´n táº­p 1","CÃ¢u há»i Ã´n táº­p 2"],"studyTips":"Gá»£i Ã½ cÃ¡ch há»c hiá»‡u quáº£"}

CHá»ˆ TRáº¢ Vá»€ JSON, KHÃ”NG CÃ“ TEXT KHÃC.
''';

    final response = await chat(message: prompt, temperature: 0.5, maxTokens: 2048);

    try {
      String jsonStr = response.trim();
      
      if (jsonStr.contains('```json')) {
        jsonStr = jsonStr.split('```json')[1].split('```')[0].trim();
      } else if (jsonStr.contains('```')) {
        jsonStr = jsonStr.split('```')[1].split('```')[0].trim();
      }
      
      final startIndex = jsonStr.indexOf('{');
      final endIndex = jsonStr.lastIndexOf('}');
      if (startIndex != -1 && endIndex != -1) {
        jsonStr = jsonStr.substring(startIndex, endIndex + 1);
      }
      
      return Map<String, dynamic>.from(jsonDecode(jsonStr));
    } catch (e) {
      return {
        'summary': response,
        'error': 'Could not parse structured summary',
      };
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ’¬ SIMPLE CHAT
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  static Future<String> simpleChat({
    required String message,
    String language = 'vi',
  }) async {
    final systemPrompt = language == 'vi' 
        ? 'Báº¡n lÃ  trá»£ lÃ½ AI thÃ¢n thiá»‡n. Tráº£ lá»i ngáº¯n gá»n, há»¯u Ã­ch báº±ng tiáº¿ng Viá»‡t.'
        : 'You are a friendly AI assistant. Respond concisely and helpfully in English.';
    
    return await chat(
      message: message,
      systemPrompt: systemPrompt,
      temperature: 0.7,
    );
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ“Š AI DATA ANALYSIS
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  static Future<String> analyzeData({
    required String data,
    required String analysisRequest,
    String language = 'vi',
  }) async {
    final systemPrompt = '''
Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch dá»¯ liá»‡u giÃ¡o dá»¥c.
PhÃ¢n tÃ­ch dá»¯ liá»‡u Ä‘Æ°á»£c cung cáº¥p vÃ  Ä‘Æ°a ra insights há»¯u Ã­ch.
Tráº£ lá»i báº±ng ${language == 'vi' ? 'tiáº¿ng Viá»‡t' : 'English'}.
Sá»­ dá»¥ng markdown Ä‘á»ƒ format cÃ¢u tráº£ lá»i.
''';

    return await chat(
      message: 'Dá»® LIá»†U:\n$data\n\nYÃŠU Cáº¦U PHÃ‚N TÃCH:\n$analysisRequest',
      systemPrompt: systemPrompt,
      temperature: 0.5,
      maxTokens: 2048,
    );
  }
}